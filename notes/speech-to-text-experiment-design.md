# Speech-to-Text Experiment Design

> The speaker outlines planned experiments for speech-to-text (STT) accuracy testing. He describes planned testing varying speech speed and simulated environmental conditions.

*Transcribed: 9 Dec 2025 16:16*

---

Okay, so just following, uh, the pattern that I've done lately of recording voice notes to, uh, document or gather efficiently context about specific projects. Uh, so these are all little components of a larger project that I'm working on with speech, but nevertheless they're very relevant, um, as I always assume someone has done, someone has like done all these experiments, right, and like gathered this data. And sometimes I find, oh, wait, no one has. That's really cool. I can try it out. So, a couple of the things that I wonder from when I'm using speech to text, uh, recognition, every day, uh, as I keep mentioning for the past year, um, is well, there's a few things. How the your speaking pace. To what extent does that influence the accuracy? Sometimes, um, I mean, I tend to speak at a sort of this pace approximately, but sometimes I've been like, well, why don't I just speak a bit quicker and I get information, you know? Um, and it makes me wonder, of course, we can just ask Chat GPT these questions nowadays, how much does your speaking pace affect WER accuracy, but I thought it'd be useful to, um, try to actually get objective data on that through a benchmark. Um, so what I'm going to do is I've just generated with Claude, uh, three source truth texts, I think. Um, probably only one is is ideal, so I'm just going to do one for the moment, but just in case there's something useful that I want to move beyond one data point for, I can uh I can use the the those other texts. But the first one here, uh which is just called technology, is fairly bland and mundane, but decent enough, I would say in terms of things I might be dictating. Um, the only difference, significant difference I see really, is that when you're using a source truth like this, this clearly isn't something I would just, you know, I wouldn't off the cuff start speaking. The rapid advancement of artificial intelligence. So it's pre-formatted or or kind of polished text, and it's not like, I need to buy eggs, um, maybe a six-pack of beer, right, which is like how when we speak naturally, we we don't work from a script. So that's the only thing that when I'm doing these evaluations, I think, mm, is it worth looking at those two, looking at natural versus uh prepare text, but for the sake of simplicity, I'm just going to work with this one. And my original, uh back of the envelopes test was to see, okay, if I read this paragraph at a normal pace, really, really fast, like I was on, you know, a combination of uh Red Bull and other substances, how would that, what are we going to get for accuracy? And then, conversely, if I speak really painfully slowly, is that actually going to work against me because I'm giving I've added a lot of silences between words, which is going to kind of make it hard for the ASR to infer punctuation, and it's giving it's it's giving the VAD, the voice activity detection, a good run for its uh money because you're getting a lot of silences that aren't intended as silences there between words. So that's another thing I'm very interested in. A lot of people would assume, well, hang on, if I just speak more slowly, it's going to make the work easier. And it'll be interesting to see if I, if the, if we can truly prove the, um, what Chat GPT claims, that that's actually not the case. You actually want to probably just go for like a normal speaking speech. The second thing, um, that I was planning on doing a proper evaluation for, and I think it's actually easier. Um, what I was going to do was annotate my voice notes, which are recorded here, there and everywhere, and would give lots of scope for saying, well, there was a huge, you know, there was a very noisy background conversation here. There was a someone was jackhammering here. Um, I have abundant examples of all of those. And what I thought I would do instead is, that's going to take such a long time to go through that I'm probably never going to do it. Um, why not just play in the background? I have these nice studio speakers, um, that are actually very loud. Why not just play, it's going to be simulated, of course, um, play a YouTube track of someone jackhammering. And I'm going to then record then, record the voice samples there to just be kind of simulations. It won't be obviously quite as good, but I'm really just interested here in, in just a very, very broad, the words per minute one is interesting. The the microphone I covered in a separate a test, i.e. to what extent does using a, um, your studio microphone versus your phone microphone. And really what I'm interested in, uh, for my app and for in, I would say in general, is a composite of all of these answers. Like, okay, what do we know about microphone, audio conditions, speaking rate. And then from that, we can get very actionable information. Like, it doesn't, yes, of course, in an ideal world, you're speaking into a professional microphone in a very quiet home environment and at a normal pace and enunciating clearly. But if we had to move that into the real world, which of these variables do we want to control against? Uh, the one thing that for my, uh, for my test that I can't really do is wind. And what I might actually do, there's happens to be a big storm on the way here, which means it's going to get very windy tomorrow if the forecasters are correct. The reason I say I can't do wind is because wind from videography, isn't just a sound, it's an actual physical pressure on the capsule and I can't simulate that through just playing a playing a, you know, a track. I might find on YouTube of like a really windy environment. Um, maybe arguably the other ones rain kind of falls into that category, too. Anything where you've got physically, um, in addition to the noise, you're going to have like a literally a kinetic movement. Um, so that one I might just initially do synthetically and then try to capture something where I'll actually just go out with my phone tomorrow and read this delightful text in, in whatever wind they're forecasting. So that's the, uh, that's the objective here, and now I will, uh, create a few recordings.
